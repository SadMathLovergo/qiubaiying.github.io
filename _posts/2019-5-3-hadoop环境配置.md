---
layout:		post
title:		hadoop环境配置
subtitle:	在ubuntu中配置hadoop环境
date:		2019-5-3
author:		P70
header-img:	img/post-bg-hacker.jpg
catalog: true
tags:
	- hadoop
---

本篇文章主要阐述在ubuntu中配置hadoop环境时遇到的一些问题，及相应的解决方案，具体的配置过程不会详细介绍，网上有大量的教程。

详细配置参数：

- Linux系统：Ubuntu 16.04.2
- Java版本：12.0.1
- Hadoop版本：Hadoop 3.2.0

## 安装过程中遇到的问题总结

### 伪分布式环境配置

Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的Java进程来运行，节点既作为NameNode也作为DataNode，读取HDFS中的文件。

Hadoop的配置文件位于**$HADOOP_HOME/etc/hadoop/**中，配置伪分布式环境需要修改**core-site.xml**和**hdfs-site.xml**2个配置文件。

其中，在**core-site.xml**中添加以下内容：

![core-site.xml配置内容](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/core-site.png?raw=true)

若不配置hadoop.tmp.dir参数，则默认使用的临时目录为/tmp/hadoop-hadoop，这个目录在重启时有可能会被系统清理掉，从而导致必须重新执行format才行，并在**hdfs-site.xml**中也指定NameNode和DataNode的路径。

在**hdfs-site.xml**中添加以下内容：

![hdfs-site.xml配置内容](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/hdfs-site.png?raw=true)

配置完毕后，执行NameNode的格式化：

`$hdfs namenode -format`

格式化成功之后，结果如下图所示，一定要出现**has been successfully formatted**的结果：

![NameNode格式化结果](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/namenode-format.png?raw=true)

开启NameNode和DataNode守护进程：

`start-dfs.sh`

启动结果如下图所示：

![dfs启动结果](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/start-dfs.png?raw=true)

注意，此过程如果出现一下WARN提示：**WARN util.NativeCodeLoader:Unable to load native-hadoop library for your platform...using builtin-java where applicable。**该WARN并不会影响Hadoop的正常使用，出现此WARN的原因是，安装的Hadoop是Release版本，其中的**libhadoop.so.1.0.0**是在32位环境下编译的，而系统是64位的系统，才会报出上述WARN，可以通过在**$HADOOP_HOME/etc/hadoop/hadoop-env.sh**中加入以下内容解决：

![hadoop-env.sh配置内容](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/hadoop-env.png?raw=true)

启动完成后，可以通过**jps**指令来查看是否启动成功，若启动成功，则会列出如下进程**NameNode、DataNode和SecondaryNameNode**，如下图所示：

![jps查询结果图](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/jps.png?raw=true)

如果没有出现NameNode或DataNode，则是因为前面的配置过程没有成功，其中，如果没有DataNode线程，则可能是因为多次执行了NameNode的格式化指令，每次执行时会在NameNode数据文件夹中(即配置文件中dfs.name.dir的路径)保存一个**current/VERSION**文件，记录clusterID，而DataNode中保存的**current/VERSION**文件中的clusterID的值是上一次格式化保存的clusterID，这样就会导致DataNode和NameNode之间的clusterID不一致，有以下两种解决方案：

- 将dfs.name.dir路径下整个dfs文件夹删除，然后重新运行NameNode的格式化指令；

- 若dfs文件夹中有重要的数据，则在dfs/name/current目录下找到VERSION文件，记录下NameNode的clusterID值，并将dfs/data/current目录下的VERSION文件中的DataNode的clustreID值替换即可；

成功启动之后，可以访问WEB界面通过http://localhost:9870来查看NameNode和DataNode信息，此外，还可以在线查看HDFS中的文件。

![在线查看](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/localhost.png?raw=true)

此处务必要注意，在老版的Hadoop中默认的localhost端口为50070，而3.2.0版的Hadoop的默认端口为9870，此处一定要注意。

在使用完毕后，请使用如下指令关闭Hadoop：

`$stop-dfs.sh`

![stop-dfs.sh](https://github.com/SadMathLovergo/SadMathLovergo.github.io/blob/master/img/2019-5-3/stop-dfs.png?raw=true)

## 参考文献

[Hadoop: Setting up a Single Node Cluster.](<https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html>)

[Ubuntu 16.04上安装Hadoop并成功运行](<https://wangchangchung.github.io/2017/09/28/Ubuntu-16-04%E4%B8%8A%E5%AE%89%E8%A3%85Hadoop%E5%B9%B6%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C/>)

